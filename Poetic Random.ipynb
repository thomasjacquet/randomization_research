{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:10:29.313532Z",
     "start_time": "2021-08-03T15:10:29.274502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>we</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word\n",
       "0     the\n",
       "1     and\n",
       "2      to\n",
       "3      of\n",
       "4       a\n",
       "5      in\n",
       "6      is\n",
       "7    that\n",
       "8     for\n",
       "9       I\n",
       "10    you\n",
       "11     it\n",
       "12   with\n",
       "13     on\n",
       "14     as\n",
       "15    are\n",
       "16     be\n",
       "17   this\n",
       "18    was\n",
       "19   have\n",
       "20     or\n",
       "21     at\n",
       "22    not\n",
       "23   your\n",
       "24   from\n",
       "25     we\n",
       "26     by\n",
       "27   will\n",
       "28    can\n",
       "29    but\n",
       "30   they\n",
       "31     an\n",
       "32     he\n",
       "33    all\n",
       "34    has\n",
       "35     if\n",
       "36  their\n",
       "37    one\n",
       "38     do\n",
       "39   more\n",
       "40    n't\n",
       "41     my\n",
       "42    his\n",
       "43     so\n",
       "44  there"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text.head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T16:48:19.061785Z",
     "start_time": "2021-08-02T16:48:19.004965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he little place went full\n",
      "or had found coming experience\n",
      "more did without usually want\n",
      "to both together natural needs\n",
      "as does real american every\n",
      "so two until four way\n",
      "have help yet child house\n",
      "your off small common market\n",
      "more each within financial through\n",
      "your off community face service\n",
      "you information says ask sure\n",
      "which through important internet had\n",
      "my her found across health\n",
      "it well often web part\n",
      "they should better works think\n",
      "a few using human play\n",
      "as only able level than\n",
      "all where change given let\n",
      "not few give plan fact\n",
      "our right case report right\n",
      "their see under price would\n",
      "which many data type each\n",
      "in get against various power\n",
      "also day provide although them\n",
      "so world called across use\n",
      "to look must form often\n",
      "your just important following both\n",
      "my said got problem large\n",
      "not just start especially each\n",
      "has may thing started yet\n",
      "more me company based old\n",
      "has long full black course\n",
      "is much come human done\n",
      "what get three offer water\n",
      "at where food run time\n",
      "their new set video year\n",
      "was many point hours since\n",
      "their time end space money\n",
      "one only keep problems over\n",
      "who its team technology them\n",
      "his look development party away\n",
      "their other experience friends week\n",
      "also another money across against\n",
      "will think second party got\n",
      "it had area office keep\n",
      "so own less website need\n",
      "but back within check together\n",
      "they its keep problem person\n",
      "your way book plan working\n",
      "in make show usually process\n"
     ]
    }
   ],
   "source": [
    "from random import randint   \n",
    "word1 = text['word'][(randint(1,54))]\n",
    "word2 = text['word'][(randint(54,154))]\n",
    "word3 = text['word'][(randint(154,300))]\n",
    "word4 = text['word'][(randint(300,499))]\n",
    "word5 = text['word'][(randint(54,300))]\n",
    "    \n",
    "for i in range(50):\n",
    "    word1 = text['word'][(randint(1,54))]\n",
    "    word2 = text['word'][(randint(54,154))]\n",
    "    word3 = text['word'][(randint(154,300))]\n",
    "    word4 = text['word'][(randint(300,499))]\n",
    "    word5 = text['word'][(randint(54,300))]\n",
    "    word_list = ['word2','word3','word4','word5']\n",
    "    print(word1,word2,word3,word4,word5)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T18:02:42.952870Z",
     "start_time": "2021-08-02T18:02:42.920410Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " def poem():\n",
    "        from random import randint   \n",
    "        from datetime import datetime\n",
    "        text = pd.read_csv(\"ai_text_test.csv\")\n",
    "        name = pd.read_csv('firstforename.csv')\n",
    "        allcities = pd.read_csv('allcities2.csv')\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"On %A %d of %B  %Y,\")\n",
    "\n",
    "        word1 = text['word'][(randint(1,54))]\n",
    "        word2 = text['word'][(randint(54,154))]\n",
    "        word3 = text['word'][(randint(154,300))]\n",
    "        word4 = text['word'][(randint(300,499))]\n",
    "        word5 = text['word'][(randint(54,300))]\n",
    "        word6 = text['word'][(randint(200,400))]\n",
    "        word7 = text['word'][(randint(154,300))]\n",
    "        word8 = text['word'][(randint(300,499))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(53*' '+word6.title(),word5.title(),word4.title())\n",
    "        print(59*' ',3*\"_\",3*'\\n')\n",
    "        print(1*'\\n',80*' '+date,3*'\\n')\n",
    "\n",
    "\n",
    "\n",
    "        strophe = 0\n",
    "        for i in range(49):\n",
    "            strophe += 1\n",
    "            if strophe == 6:\n",
    "                strophe = 0\n",
    "                print(\"\\n\")\n",
    "            word1 = text['word'][(randint(1,54))]\n",
    "            word2 = text['word'][(randint(54,154))]\n",
    "            word3 = text['word'][(randint(154,300))]\n",
    "            word4 = text['word'][(randint(300,499))]\n",
    "            word5 = text['word'][(randint(54,300))]\n",
    "            word6 = text['word'][(randint(200,400))]\n",
    "            word7 = text['word'][(randint(154,300))]\n",
    "            word8 = text['word'][(randint(300,499))]\n",
    "            poet = name['FirstForename'][(randint(1,248419))]\n",
    "            poet_name = allcities['0'][(randint(54,300))]\n",
    "            print(word7.title(),word1,word3,word6,word8,word2,word5)\n",
    "\n",
    "\n",
    "\n",
    "print(8*'\\n',80*' '+poet.title(),poet_name.title(),3*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:12:39.566546Z",
     "start_time": "2021-08-03T15:12:39.266928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Times Each Mind\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Data from never thing include through government\n",
      "Point that during quality fun see being\n",
      "Set if however university bring could man\n",
      "Play is women given various see her\n",
      "Left his having house party new want\n",
      "\n",
      "\n",
      "Important he three across url look less\n",
      "Experience they fact city coming think school\n",
      "Services have women available issues well around\n",
      "Person an ever four center use make\n",
      "Left if against plan center many got\n",
      "Play of under read check were school\n",
      "\n",
      "\n",
      "Keep more show country true many care\n",
      "Case to game left page him because\n",
      "Real do called times level other world\n",
      "Person we number tell url before food\n",
      "Others we might children taking take people\n",
      "System can again possible room into need\n",
      "\n",
      "\n",
      "Days by might car main going power\n",
      "Already can based went addition best free\n",
      "Community this let site due its being\n",
      "Ca from support program companies little city\n",
      "Experience has old support main were food\n",
      "Against to ca url mind she try\n",
      "\n",
      "\n",
      "Start this school young taken part find\n",
      "Open n't family group everyone life money\n",
      "Love from love students especially now might\n",
      "Money about play future general now her\n",
      "Open so local government comes both well\n",
      "Development had change either trying down does\n",
      "\n",
      "\n",
      "Small have often having someone need way\n",
      "Experience with house small result some after\n",
      "Without that food taking common need been\n",
      "Community that again care news going found\n",
      "Person out today came ask both much\n",
      "Order to means point view go help\n",
      "\n",
      "\n",
      "Doing so development area night had during\n",
      "Am but once run url since today\n",
      "Area as having development went need far\n",
      "Since what family person quite off make\n",
      "Sure if research due million most even\n",
      "Play we care fact certain right case\n",
      "\n",
      "\n",
      "Doing all service far least me had\n",
      "During as might including further since like\n",
      "School an case problem young little used\n",
      "Open can thing whole share another today\n",
      "System do community working quality did fact\n",
      "Power what less example amount over take\n",
      "\n",
      "\n",
      "Free and let enough website best never\n",
      "Love with full website usually business business\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.poem()>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T19:11:53.702307Z",
     "start_time": "2021-08-02T19:11:53.514253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Fact Say Whole\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Monday 02 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Under or looking change history get such\n",
      "Several in end support management may food\n",
      "Without with real energy months being best\n",
      "Open be body ca nothing even health\n",
      "Social your got across games day how\n",
      "\n",
      "\n",
      "Put from second future live few different\n",
      "Something which company possible seen every something\n",
      "Come on come research report own full\n",
      "Once one second several taking each times\n",
      "Having not using start results does state\n",
      "Against from within music kind business little\n",
      "\n",
      "\n",
      "Says on development easy trying where services\n",
      "Better by side management close both said\n",
      "Course his area university media them full\n",
      "Online by open comes learn could between\n",
      "Called out open general known work enough\n",
      "Show is number yet industry both here\n",
      "\n",
      "\n",
      "Sure have enough per create how long\n",
      "Lot for full point general still been\n",
      "Number it process looking technology other own\n",
      "Course one times american job first children\n",
      "Children also keep data games most sure\n",
      "Company when keep provide addition way day\n",
      "\n",
      "\n",
      "Along not always quite head because school\n",
      "School all during call simple first down\n",
      "Fact an family fact hand look little\n",
      "Days they found getting education new things\n",
      "Using there ca provide management best got\n",
      "Person up experience music especially each another\n",
      "\n",
      "\n",
      "Money his under available international two were\n",
      "Again also available following living into needs\n",
      "Book or next night special much part\n",
      "Development and provide friends went before would\n",
      "Making by says along add get city\n",
      "Person in open started building day why\n",
      "\n",
      "\n",
      "Come we say training list make service\n",
      "However your place product whether make put\n",
      "Site from far energy understand people god\n",
      "Book had game house share right than\n",
      "Students have already away kind another must\n",
      "Money n't times against inside take day\n",
      "\n",
      "\n",
      "Come I something experience add help food\n",
      "Services on research taking s other local\n",
      "Put one doing looking makes said services\n",
      "Needs we man per financial very years\n",
      "Getting our social learn everyone those much\n",
      "Making are sure social financial two children\n",
      "\n",
      "\n",
      "Days at top house university part how\n",
      "Play for care far among long children\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.poem()>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T20:37:20.332571Z",
     "start_time": "2021-08-02T20:37:20.308506Z"
    }
   },
   "outputs": [],
   "source": [
    " def poem2():\n",
    "        from random import randint   \n",
    "        from datetime import datetime\n",
    "        join_text = pd.read_csv(\"ai_text_test.csv\")\n",
    "        text = pd.read_csv(\"common-english-words-csv.csv\")\n",
    "        name = pd.read_csv('firstforename.csv')\n",
    "        allcities = pd.read_csv('allcities2.csv')\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"On %A %d of %B  %Y,\")\n",
    "\n",
    "        word1 = join_text['word'][(randint(1,54))]\n",
    "        \n",
    "        word2 = text['word'][(randint(54,154))]\n",
    "        word3 = text['word'][(randint(154,300))]\n",
    "        word4 = text['word'][(randint(300,499))]\n",
    "        word5 = text['word'][(randint(54,300))]\n",
    "        word6 = text['word'][(randint(200,400))]\n",
    "        word7 = text['word'][(randint(154,300))]\n",
    "        word8 = text['word'][(randint(300,499))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(53*' '+word6.title(),word2.title(),word8.title())\n",
    "        print(59*' ',3*\"_\",3*'\\n')\n",
    "        print(1*'\\n',80*' '+date,3*'\\n')\n",
    "\n",
    "\n",
    "\n",
    "        strophe = 0\n",
    "        for i in range(64):\n",
    "            strophe += 1\n",
    "            if strophe == 4:\n",
    "                strophe = 0\n",
    "                print(\"\\n\")\n",
    "            word1 = text['word'][(randint(1,54))]\n",
    "            word2 = text['word'][(randint(54,154))]\n",
    "            word3 = text['word'][(randint(154,300))]\n",
    "            word4 = text['word'][(randint(300,499))]\n",
    "            word5 = text['word'][(randint(499,800))]\n",
    "            word6 = text['word'][(randint(800,1500))]\n",
    "            word7 = text['word'][(randint(1500,2600))]\n",
    "            word8 = text['word'][(randint(2600,3999))]\n",
    "            word9 = join_text['word'][(randint(1,20))]\n",
    "            word10 = join_text['word'][(randint(1,54))]\n",
    "            poet = name['FirstForename'][(randint(1,248419))]\n",
    "            poet_name = allcities['0'][(randint(54,300))]\n",
    "            print(word7.title(),word1,word3,word9,word6,word2,word10,word8,word5)\n",
    "\n",
    "\n",
    "\n",
    "        print(8*'\\n',80*' '+poet.title(),poet_name.title(),3*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T18:18:44.652248Z",
     "start_time": "2021-08-02T18:18:44.394063Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Love While Possible\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Monday 02 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Overall one head you weather see you beam manager\n",
      "Sink a study and credit only of lens certain\n",
      "Hill know each is inside way n't whoever husband\n",
      "\n",
      "\n",
      "Hero that against of greatest only we partially administration\n",
      "Ourselves one under with principle people our lemon loss\n",
      "Honest my information as audience between is agriculture news\n",
      "Entirely I house is educational keep by realm laugh\n",
      "\n",
      "\n",
      "Label year live with classroom new are qualify feeling\n",
      "Concentrate up right it Ms new has custom section\n",
      "Regard at several on tie two have gentle environmental\n",
      "Chemical up job was nine another an Dutch meeting\n",
      "\n",
      "\n",
      "Champion as during you surface may your generous industry\n",
      "Square when business is exist only has starting ok\n",
      "Decline from side I weather our n't galaxy sound\n",
      "Bench them must and pocket come had banking blue\n",
      "\n",
      "\n",
      "Deputy what game a block still of adolescent stock\n",
      "Equal if head with reporter need if liquid trade\n",
      "Solar do move this announce old from elevator single\n",
      "Chocolate my car it married something by alliance rather\n",
      "\n",
      "\n",
      "Extent time line on income here a forehead staff\n",
      "Killer at though was facility big his borrow manager\n",
      "Topic but right that Russian world about speculation board\n",
      "Tourist to hear as strange good so skirt enjoy\n",
      "\n",
      "\n",
      "Specifically them change I adult take will database agency\n",
      "Regarding that until you participate see up shit training\n",
      "Careful with Mr on charge own will drunk Congress\n",
      "Comparison she continue in method keep who medal seven\n",
      "\n",
      "\n",
      "Definition to program this remind no and echo campaign\n",
      "Islamic we water and married work what costly despite\n",
      "Imply her place on insurance give we fitness usually\n",
      "Dad by house and memory turn my monument serious\n",
      "\n",
      "\n",
      "Employ go information you purpose put I restrict rather\n",
      "Cloud they team this associate family if placement financial\n",
      "Moon which member be cancer state to dynamic general\n",
      "Relevant her during I collect old n't workshop thought\n",
      "\n",
      "\n",
      "Declare when night with key those has swear prove\n",
      "Slave them head was citizen him there flash laugh\n",
      "Cousin go whether it failure call had homeland environmental\n",
      "Wrap go kid on writing more was softly nature\n",
      "\n",
      "\n",
      "Settlement to hold with speech state your flip practice\n",
      "Debt them under be principle our as drain usually\n",
      "Abandon which minute are nod may who bitter campaign\n",
      "Silence with water and trip after we o'clock ok\n",
      "\n",
      "\n",
      "Meanwhile from face be tool take who decrease scene\n",
      "Arrest they each are victory keep one gentle animal\n",
      "Implement year almost was beginning work or fever thousand\n",
      "Bean a often to eventually call that sequence religious\n",
      "\n",
      "\n",
      "Beer or line I prison last be reportedly soon\n",
      "Pure we almost be insurance why their scramble approach\n",
      "Chart if under or date him has makeup song\n",
      "Innocent up business to guard between with suburb data\n",
      "\n",
      "\n",
      "Designer them American a knee try but trash campaign\n",
      "Nose we information that facility work I monster forward\n",
      "Pilot who mother and address should out downtown entire\n",
      "Dust can ever to handle never can interior beyond\n",
      "\n",
      "\n",
      "Insight when until on discover any on exact certainly\n",
      "Spokesman but game be western call have sharply risk\n",
      "Tap about idea of burn down they exact amount\n",
      "Album this business and marry three in motivate goal\n",
      "\n",
      "\n",
      "Ceremony in point in female really has pig husband\n",
      "Debt it five for modern put one elevator song\n",
      "External it program it chair put not nail TV\n",
      "Proper do move have circle call he stumble myself\n",
      "\n",
      "\n",
      "Trust I case to final while if gaze choose\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Janine Baghdad \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T19:07:21.795600Z",
     "start_time": "2021-08-02T19:07:21.544693Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Five Man Everyone\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Monday 02 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Defensive them next as grab much in instinct section\n",
      "Entry I follow this western tell out wound either\n",
      "Kiss I hour that knee no from format miss\n",
      "\n",
      "\n",
      "Bury can month have marry good so attraction either\n",
      "Distant know house I wonderful most up planner laugh\n",
      "Mark so million in abuse than or discourse cup\n",
      "Transform their under I minority call had concrete throw\n",
      "\n",
      "\n",
      "Disorder for lot was opinion any there excitement involve\n",
      "Flag or nothing in grab talk had appointment response\n",
      "Boot go off was burn country not bonus save\n",
      "Muscle at American or Christmas people who alongside west\n",
      "\n",
      "\n",
      "Tournament would long for sexual old they charity feeling\n",
      "Saving their away for somebody another it whip fine\n",
      "Depression for week is terms thing to written herself\n",
      "Journey when area and ignore try one legitimate dead\n",
      "\n",
      "\n",
      "Tea me several with key talk what legislative rest\n",
      "Ceremony with job is birth family my weaken entire\n",
      "Award for business of theory own will devote shoot\n",
      "Pace there night that park most has strictly daughter\n",
      "\n",
      "\n",
      "Definitely or learn is shadow us our eating meeting\n",
      "Load it whether of directly now is reservation store\n",
      "Disability a part of sweet more my pencil executive\n",
      "Sudden can national that civil many to gathering bill\n",
      "\n",
      "\n",
      "React in line with lift world on tackle available\n",
      "Cite so social be express group be drinking central\n",
      "Core she issue you software call one clerk poor\n",
      "Developing time until for unless state up fitness population\n",
      "\n",
      "\n",
      "Mail in different I professional way you romantic stock\n",
      "Occupy not game you owner become out loyalty available\n",
      "Notion my large to direction your so glove central\n",
      "Jewish them play to chief should this fifteen type\n",
      "\n",
      "\n",
      "Provision one today as dangerous woman but retail past\n",
      "Boot if once on athlete back can decrease east\n",
      "Decline know live a somebody could or nonprofit physical\n",
      "Quit their though on United come for angel available\n",
      "\n",
      "\n",
      "Buck it president or invite over there vulnerable north\n",
      "Assistant will team to middle why with sidewalk color\n",
      "Massive go least have train man on towel easy\n",
      "Preserve will hand on reflect more that rose crime\n",
      "\n",
      "\n",
      "Anger one president be weight high can membership test\n",
      "Wedding a house of pattern first this recipient cold\n",
      "Self time both or justice how it insert doctor\n",
      "Solar by parent for faith look it fleet language\n",
      "\n",
      "\n",
      "Teaspoon with before this discussion thing have functional quite\n",
      "Seriously with again on threat high are doll patient\n",
      "Emotion it business be regular really I angel religious\n",
      "Bread my bring and particular these up wherever discuss\n",
      "\n",
      "\n",
      "Contrast not provide of beginning than by patrol term\n",
      "Bullet make provide have avoid really on sibling thus\n",
      "Blind at job are establish put at excited choose\n",
      "Kick on week in western no up leather message\n",
      "\n",
      "\n",
      "Jewish in line in influence own what precious series\n",
      "Broken time father is promote its up horrible democratic\n",
      "Convert his side with mom over what candy artist\n",
      "Disaster they community I whom where have bureau term\n",
      "\n",
      "\n",
      "Definition them word of procedure after you adequate patient\n",
      "King for stand this suit then by workplace period\n",
      "Commander by social was Christmas back of experienced forward\n",
      "Thick their parent is insurance ask out damn exactly\n",
      "\n",
      "\n",
      "Correspondent up today is sweet good will elephant focus\n",
      "Toy a move or maintain turn but ladder describe\n",
      "Inspire you mother you competition own they sake scene\n",
      "Frequently one fact I inside most has weaken near\n",
      "\n",
      "\n",
      "Neither not case on desk may what ankle despite\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Brooke Shenyang \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:13:18.751240Z",
     "start_time": "2021-08-03T15:13:18.371234Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Black Work Economic\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Duty this point in straight out by vanish doctor\n",
      "Impression she end in dream begin if fleet operation\n",
      "Guilty all right a desire student a educate doctor\n",
      "\n",
      "\n",
      "Bet which hold of therefore group our irony simply\n",
      "Twin from kid that mental mean be beg tree\n",
      "Crash time meet that facility try n't bee population\n",
      "Experiment would American for previous people it bite simply\n",
      "\n",
      "\n",
      "Effectively so business are researcher your can precise west\n",
      "Ring year different it committee then be automatically south\n",
      "Enormous there little as horse while to absolute crime\n",
      "Planning if young as fan work our medication fine\n",
      "\n",
      "\n",
      "Defensive or during to suffer leave they pin usually\n",
      "Teaspoon on show have science feel and boom street\n",
      "Adapt by such or European first you refrigerator fill\n",
      "Oppose so money was hire where there herb summer\n",
      "\n",
      "\n",
      "Cake he study that failure than can conspiracy cup\n",
      "Blind on money this shot people they motivate realize\n",
      "Defensive my home for fat ask are amid benefit\n",
      "Relative go name in encourage high we amid indicate\n",
      "\n",
      "\n",
      "Joke we young you budget life he nominee window\n",
      "Enormous some until on document between have piano laugh\n",
      "Educator make watch that British something they deadline rise\n",
      "Convince would every and importance through on diamond media\n",
      "\n",
      "\n",
      "Fiber me money with annual begin they correlation career\n",
      "Symbol time before are nobody really up tide author\n",
      "Emergency for fact as specific here their privilege leg\n",
      "Trust know home on ear same of delicate save\n",
      "\n",
      "\n",
      "Tire which each or option many but stadium listen\n",
      "Perfectly by book is shoulder woman from rent despite\n",
      "Unfortunately or father to shape into this rhythm recently\n",
      "Contrast but idea are software two to decent sport\n",
      "\n",
      "\n",
      "Parking do month with breath people to someday thought\n",
      "Retire about information of property world if venture pressure\n",
      "Tight by before for touch really if disk sport\n",
      "Senator not set to commit too by pond upon\n",
      "\n",
      "\n",
      "Link say company you nor too if radiation deal\n",
      "Mix some program on survive last my magic strategy\n",
      "Fifth some government in please still or disappointed authority\n",
      "Recognition think start you citizen us will aide single\n",
      "\n",
      "\n",
      "Previously his five and chair let can liquid laugh\n",
      "Sweep to must I wish really so full-time nature\n",
      "Peer will book as sing much can oak nearly\n",
      "Tired his number for bone keep it remark defense\n",
      "\n",
      "\n",
      "Proper go yes are Mrs between he ghost news\n",
      "Sale by game a memory country if bee factor\n",
      "Desert by large have debate why a fortunately third\n",
      "Stair which member to equipment because so skip push\n",
      "\n",
      "\n",
      "Addition up word have directly back my sexy either\n",
      "Maker but system of pool woman my attendance myself\n",
      "Sweep when several was none state are soup glass\n",
      "Moon or believe are pain high if revolutionary note\n",
      "\n",
      "\n",
      "Visible at minute a colleague take and runner fight\n",
      "Quietly he kind on beginning two will sodium check\n",
      "Literally there hear and employee tell and boast character\n",
      "Entry my friend are sing begin is mount particularly\n",
      "\n",
      "\n",
      "Illness if around on nice life was notebook song\n",
      "Illustrate if home it labor then if likewise easy\n",
      "Arrest when once are introduce down had biology ability\n",
      "Switch up four as video try an brilliant claim\n",
      "\n",
      "\n",
      "Capture would before that below no so counsel disease\n",
      "Reject you idea to style world if whip order\n",
      "Alcohol year side a kitchen problem with echo period\n",
      "Implement get yes I map down they hunter cup\n",
      "\n",
      "\n",
      "Graduate in understand of critic something there someday century\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Inaya Xinyang \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:14:04.961804Z",
     "start_time": "2021-08-03T15:14:04.681491Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Change Out Development\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Twenty a hour on mistake then will scope compare\n",
      "Relevant as whether are skin mean and hug color\n",
      "Alcohol that continue this pocket ask are acceptance left\n",
      "\n",
      "\n",
      "Wedding he four a expression man our dump indeed\n",
      "Latin he idea on additional old was glory street\n",
      "Minister but fact it insurance try as spite whatever\n",
      "Dimension make before for main thing to jazz officer\n",
      "\n",
      "\n",
      "External by night on completely still my temple drop\n",
      "Description some nothing in army after on flood forget\n",
      "Defend so head and surround should of traditionally doctor\n",
      "Evaluation not hour have credit after one minimize shoot\n",
      "\n",
      "\n",
      "Presentation can provide are skin student for speculation south\n",
      "Vary we every as fly keep but stimulate north\n",
      "Trend she little that democracy most out privacy fire\n",
      "Permanent about room in device out it tray usually\n",
      "\n",
      "\n",
      "Implication all far was slowly own a harsh film\n",
      "Assign so stand in shop great are chef either\n",
      "Rare my fact was handle should has tail animal\n",
      "Advise have line for tend state a legitimate enter\n",
      "\n",
      "\n",
      "Profit from member for purpose too we cloth legal\n",
      "Recommend up change with path while was nest future\n",
      "Volunteer they night I annual put an hidden environmental\n",
      "Numerous from continue with politics way by everyday common\n",
      "\n",
      "\n",
      "Veteran her later I ride other this cage bed\n",
      "Journal as follow for demand our can ski amount\n",
      "Stupid or ago this poll big it revelation piece\n",
      "Recipe we place have citizen now also chapter easy\n",
      "\n",
      "\n",
      "Singer I provide in panel now a wise approach\n",
      "Contemporary go car of mental here n't rack per\n",
      "Length up political in Christmas really or carve private\n",
      "Desert say young in management life all diagnose scene\n",
      "\n",
      "\n",
      "Virtually do far have background our do carbon guess\n",
      "Expectation their name are statement him can monster central\n",
      "Relevant so Mr that session three about wisdom technology\n",
      "Catholic when minute is protection him my dot standard\n",
      "\n",
      "\n",
      "Elite can parent was yourself day also appoint size\n",
      "Pant or kid is commit just their edition prove\n",
      "Signal who story are reveal no for booth indicate\n",
      "Psychological we always and direction any when strict realize\n",
      "\n",
      "\n",
      "Stranger people program be Mrs come they dump page\n",
      "Protein me issue is football woman was candy share\n",
      "Bench which word or fly mean can interior religious\n",
      "Passenger her might to lack could who ladder pretty\n",
      "\n",
      "\n",
      "Appeal year such with software only not cope TV\n",
      "Spending which anything have nobody family I motor evidence\n",
      "Comfortable me social be Democrat many of bite gun\n",
      "Reference about might are promise use their dissolve identify\n",
      "\n",
      "\n",
      "Holy so again be shape then to sixth particularly\n",
      "Silver by national it sorry any that hint race\n",
      "Recommend all community have green new there remark identify\n",
      "Joy you hold and obtain many you chef environmental\n",
      "\n",
      "\n",
      "Brand will today or scientific just who happiness computer\n",
      "Newly know right for wine three with supervisor bed\n",
      "Existing will often that onto country n't doorway represent\n",
      "Proper do show for discover call an unfair organization\n",
      "\n",
      "\n",
      "Holiday from hear of wind through that uncertainty network\n",
      "Hat on point and limit talk from hypothesis agency\n",
      "Elite with week have critic something who sexually population\n",
      "Extent them show a wave look is whip catch\n",
      "\n",
      "\n",
      "Teen one every that avoid find also owe anyone\n",
      "Copy can service was object most who horrible dead\n",
      "Resort this whether to relatively because not intelligent fund\n",
      "Violate all idea on eventually any by marketplace leg\n",
      "\n",
      "\n",
      "Generate from number have yesterday just your invitation cold\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Anscar Huizhou \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poem2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T20:40:39.853292Z",
     "start_time": "2021-08-02T20:40:39.828362Z"
    }
   },
   "outputs": [],
   "source": [
    " def haiku():\n",
    "        from random import randint   \n",
    "        from datetime import datetime\n",
    "        join_text = pd.read_csv(\"ai_text_test.csv\")\n",
    "        text = pd.read_csv(\"common-english-words-csv.csv\")\n",
    "        name = pd.read_csv('firstforename.csv')\n",
    "        allcities = pd.read_csv('allcities2.csv')\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"On %A %d of %B  %Y,\")\n",
    "\n",
    "        word1 = join_text['word'][(randint(1,54))]\n",
    "        \n",
    "        word2 = text['word'][(randint(54,154))]\n",
    "        word3 = text['word'][(randint(154,300))]\n",
    "        word4 = text['word'][(randint(300,499))]\n",
    "        word5 = text['word'][(randint(54,300))]\n",
    "        word6 = text['word'][(randint(200,400))]\n",
    "        word7 = text['word'][(randint(154,300))]\n",
    "        word8 = text['word'][(randint(300,499))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(53*' '+word6.title(),word2.title(),word8.title())\n",
    "        print(59*' ',3*\"_\",3*'\\n')\n",
    "        print(1*'\\n',80*' '+date,3*'\\n')\n",
    "\n",
    "\n",
    "\n",
    "        strophe = 0\n",
    "        for i in range(8):\n",
    "            strophe += 1\n",
    "            if strophe == 5:\n",
    "                strophe = 0\n",
    "                print(\"\\n\")\n",
    "            word1 = text['word'][(randint(1,54))]\n",
    "            word2 = text['word'][(randint(54,154))]\n",
    "            word3 = text['word'][(randint(154,300))]\n",
    "            word4 = text['word'][(randint(300,499))]\n",
    "            word5 = text['word'][(randint(499,800))]\n",
    "            word6 = text['word'][(randint(800,1500))]\n",
    "            word7 = text['word'][(randint(1500,2600))]\n",
    "            word8 = text['word'][(randint(2600,3999))]\n",
    "            word9 = join_text['word'][(randint(1,20))]\n",
    "            word10 = join_text['word'][(randint(1,54))]\n",
    "            poet = name['FirstForename'][(randint(1,248419))]\n",
    "            poet_name = allcities['0'][(randint(54,300))]\n",
    "            print(word7.title(),word1,word3,word10,word6)\n",
    "\n",
    "\n",
    "\n",
    "        print(8*'\\n',80*' '+poet.title(),poet_name.title(),3*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-02T20:41:15.724342Z",
     "start_time": "2021-08-02T20:41:15.558337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Death State Effect\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Monday 02 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Engineering up once and European\n",
      "Propose some story in recall\n",
      "Fairly if small you supply\n",
      "Participation who money you track\n",
      "\n",
      "\n",
      "Grant her question their perspective\n",
      "Secretary to story as knee\n",
      "Treaty their American out consequence\n",
      "Boundary at hand they sample\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Kaidey Shaoguan \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "haiku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:16:15.474822Z",
     "start_time": "2021-08-03T15:16:15.271363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Plan New Second\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Shell would under what folk\n",
      "Expansion as hour was lots\n",
      "Contemporary make little to reflect\n",
      "Partnership not system as increasingly\n",
      "\n",
      "\n",
      "Rough can lose in participant\n",
      "Technical would team also refuse\n",
      "Consultant can program has additional\n",
      "Mail they place my reality\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Reese Jiaozuo \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "haiku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:32:48.749544Z",
     "start_time": "2021-08-03T15:32:48.727567Z"
    }
   },
   "outputs": [],
   "source": [
    " def sonnet():\n",
    "        from random import randint   \n",
    "        from datetime import datetime\n",
    "        join_text = pd.read_csv(\"ai_text_test.csv\")\n",
    "        text = pd.read_csv(\"common-english-words-csv.csv\")\n",
    "        name = pd.read_csv('firstforename.csv')\n",
    "        allcities = pd.read_csv('allcities2.csv')\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"On %A %d of %B  %Y,\")\n",
    "\n",
    "        word1 = join_text['word'][(randint(1,54))]\n",
    "        \n",
    "        word2 = text['word'][(randint(54,154))]\n",
    "        word3 = text['word'][(randint(154,300))]\n",
    "        word4 = text['word'][(randint(300,499))]\n",
    "        word5 = text['word'][(randint(54,300))]\n",
    "        word6 = text['word'][(randint(200,400))]\n",
    "        word7 = text['word'][(randint(154,300))]\n",
    "        word8 = text['word'][(randint(300,499))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(53*' '+word8.title(),word6.title())\n",
    "        print(59*' ',3*\"_\",3*'\\n')\n",
    "        print(1*'\\n',80*' '+date,3*'\\n')\n",
    "\n",
    "\n",
    "\n",
    "        strophe = 0\n",
    "        for i in range(14):\n",
    "            strophe += 1\n",
    "            if strophe == 5 or strophe == 9:\n",
    "                print(\"\\n\")\n",
    "            elif strophe == 12:\n",
    "                print(\"\\n\")\n",
    "            word1 = text['word'][(randint(1,54))]\n",
    "            word2 = text['word'][(randint(54,154))]\n",
    "            word3 = text['word'][(randint(154,300))]\n",
    "            word4 = text['word'][(randint(300,499))]\n",
    "            word5 = text['word'][(randint(499,800))]\n",
    "            word6 = text['word'][(randint(800,1500))]\n",
    "            word7 = text['word'][(randint(1500,2600))]\n",
    "            word8 = text['word'][(randint(2600,3999))]\n",
    "            word9 = join_text['word'][(randint(1,20))]\n",
    "            word10 = join_text['word'][(randint(1,54))]\n",
    "            poet = name['FirstForename'][(randint(1,248419))]\n",
    "            poet_name = allcities['0'][(randint(54,300))]\n",
    "            print(word7.title(),word1,word3,word10,word9,word4,word6)\n",
    "\n",
    "\n",
    "\n",
    "        print(8*'\\n',80*' '+poet.title(),poet_name.title(),3*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:29:29.516936Z",
     "start_time": "2021-08-03T15:29:29.280089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Walk Return Us\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Possess know least more of control address\n",
      "Reject say long his is center discover\n",
      "Engineer get Mr an and raise science\n",
      "Delivery some large or in sense desk\n",
      "\n",
      "\n",
      "Aim year small their that wife painting\n",
      "Coalition from often is this town judge\n",
      "Cooperation not again is it morning neighborhood\n",
      "False some problem when in die researcher\n",
      "\n",
      "\n",
      "Canadian a write what of maybe negative\n",
      "Bike would system I as agree athlete\n",
      "Consideration up week he with return repeat\n",
      "\n",
      "\n",
      "Restore not today what this special deny\n",
      "Advertising make hold can a pass quarter\n",
      "Consistent up play to to remain lack\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Patsy Chaozhou \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sonnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:33:11.471059Z",
     "start_time": "2021-08-03T15:33:11.274518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Military Experience\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Award their question there is offer release\n",
      "Busy go almost up to international willing\n",
      "Found time bad which it event camera\n",
      "Ad you house more and themselves intend\n",
      "\n",
      "\n",
      "Bomb as story to or difference Christmas\n",
      "Height about minute if or person connection\n",
      "Portrait you American it have role fuel\n",
      "Illness me head more have care species\n",
      "\n",
      "\n",
      "Guarantee think question so that explain marry\n",
      "Universal by ago your you economic lift\n",
      "Mirror them different do for rate marry\n",
      "\n",
      "\n",
      "Slide go father had and position chairman\n",
      "Waste have happen but in air Christmas\n",
      "Throat time law more that appear partner\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Olliver Meishan \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sonnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T15:34:36.570670Z",
     "start_time": "2021-08-03T15:34:36.331205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Remain Different\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Tuesday 03 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Afford she yet from to six committee\n",
      "Dad them small you was matter importance\n",
      "Destruction not understand you you remain particular\n",
      "Expectation what however in was mind prime\n",
      "\n",
      "\n",
      "Difficulty he until our was receive crowd\n",
      "Bean that stand so or eat wine\n",
      "Craft know nothing an I join wind\n",
      "Ceiling what problem n't is price medicine\n",
      "\n",
      "\n",
      "Destruction in job they you suggest unless\n",
      "Variable for whether I that die candidate\n",
      "Existence about month be be explain mission\n",
      "\n",
      "\n",
      "Passion make best we for door youth\n",
      "Analyst have word was have maybe fan\n",
      "Revenue do least be in moment shape\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Walter Dallas \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sonnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T11:41:17.001654Z",
     "start_time": "2021-08-04T11:41:16.727389Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     Air Sense\n",
      "                                                            ___ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 On Wednesday 04 of August  2021, \n",
      "\n",
      "\n",
      "\n",
      "Comprehensive her later this is within politics\n",
      "Flow their right are I health dry\n",
      "Stake what head if for spend associate\n",
      "Towards as story so have especially original\n",
      "\n",
      "\n",
      "Unfortunately in since have and age twice\n",
      "Opponent can end are in position abuse\n",
      "Mood as political their that everyone search\n",
      "Vegetable as head by in enough shake\n",
      "\n",
      "\n",
      "Employment we house out in thank management\n",
      "Speaker up believe at I class camera\n",
      "Apparent at kind his this effort writing\n",
      "\n",
      "\n",
      "Creature me until which to speak chair\n",
      "Rely do under was you grow emerge\n",
      "Difficulty who idea or a drug quiet\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                 Zara-Louise Montral \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sonnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T11:41:08.288761Z",
     "start_time": "2021-08-04T11:41:08.067315Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jacqu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T23:40:04.451649Z",
     "start_time": "2021-08-03T23:40:04.421712Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " def prose():\n",
    "        from randomsentence.sentence_maker import SentenceMaker\n",
    "        from randomsentence.sentence_tools import SentenceTools\n",
    "        from random import randint   \n",
    "        from datetime import datetime\n",
    "        sentence_maker = SentenceMaker()\n",
    "        sentence_tools = SentenceTools()\n",
    "        join_text = pd.read_csv(\"ai_text_test.csv\")\n",
    "        text = pd.read_csv(\"common-english-words-csv.csv\")\n",
    "        name = pd.read_csv('firstforename.csv')\n",
    "        allcities = pd.read_csv('allcities2.csv')\n",
    "        now = datetime.now()\n",
    "        date = now.strftime(\"On %A %d of %B  %Y,\")\n",
    "\n",
    "        word1 = join_text['word'][(randint(1,54))]\n",
    "        \n",
    "        word2 = text['word'][(randint(54,154))]\n",
    "        word3 = text['word'][(randint(154,300))]\n",
    "        word4 = text['word'][(randint(300,499))]\n",
    "        word5 = text['word'][(randint(54,300))]\n",
    "        word6 = text['word'][(randint(200,400))]\n",
    "        word7 = text['word'][(randint(154,300))]\n",
    "        word8 = text['word'][(randint(300,499))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(53*' '+word8.title(),word6.title())\n",
    "        print(59*' ',3*\"_\",3*'\\n')\n",
    "        print(1*'\\n',80*' '+date,3*'\\n')\n",
    "\n",
    "\n",
    "\n",
    "        strophe = 0\n",
    "        for i in range(14):\n",
    "            strophe += 1\n",
    "            if strophe == 5 or strophe == 9:\n",
    "                print(\"\\n\")\n",
    "            elif strophe == 12:\n",
    "                print(\"\\n\")\n",
    "            word1 = text['word'][(randint(1,54))]\n",
    "            word2 = text['word'][(randint(54,154))]\n",
    "            word3 = text['word'][(randint(154,300))]\n",
    "            word4 = text['word'][(randint(300,499))]\n",
    "            word5 = text['word'][(randint(499,800))]\n",
    "            word6 = text['word'][(randint(800,1500))]\n",
    "            word7 = text['word'][(randint(1500,2600))]\n",
    "            word8 = text['word'][(randint(2600,3999))]\n",
    "            word9 = join_text['word'][(randint(1,20))]\n",
    "            word10 = join_text['word'][(randint(1,54))]\n",
    "            poet = name['FirstForename'][(randint(1,248419))]\n",
    "            poet_name = allcities['0'][(randint(54,300))]\n",
    "            tagged_sentence = sentence_maker.from_keyword_list([word6, word5, word7, word4])\n",
    "            print(tagged_sentence)\n",
    "\n",
    "\n",
    "        print(8*'\\n',80*' '+poet.title(),poet_name.title(),3*'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T11:01:07.889705Z",
     "start_time": "2021-08-04T11:01:00.986858Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stdbuf was not found; communication with perl may hang due to stdio buffering.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Le fichier spcifi est introuvable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-292-260ba8740c67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-290-07139371d63c>\u001b[0m in \u001b[0;36mprose\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m        \u001b[0msentence_maker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceMaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m        \u001b[0msentence_tools\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTools\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m        \u001b[0mjoin_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ai_text_test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m        \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"common-english-words-csv.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\randomsentence\\sentence_tools.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSentenceTools\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMosesDetokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdetokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mosestokenizer\\detokenizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# -b = disable output buffering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"perl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-q\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-b\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\toolwrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, argv, encoding, start, cwd, stdbuf, stderr, env)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_full_class_name_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\toolwrapper.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         self.proc = subprocess.Popen(\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_real_argv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mstdin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1305\u001b[0m             \u001b[1;31m# Start the process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m                                          \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Le fichier spcifi est introuvable"
     ]
    }
   ],
   "source": [
    "prose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-03T23:35:03.047633Z",
     "start_time": "2021-08-03T23:35:03.030713Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stdbuf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-283-ac2dc9374f40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstdbuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stdbuf'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
